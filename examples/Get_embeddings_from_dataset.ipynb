{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get embeddings from dataset\n",
    "\n",
    "This notebook gives an example on how to get embeddings from a large dataset.\n",
    "\n",
    "\n",
    "## 1. Load the dataset\n",
    "\n",
    "The dataset used in this example is [fine-food reviews](https://www.kaggle.com/snap/amazon-fine-food-reviews) from Amazon. The dataset contains a total of 568,454 food reviews Amazon users left up to October 2012. We will use a subset of this dataset, consisting of 1,000 most recent reviews for illustration purposes. The reviews are in English and tend to be positive or negative. Each review has a ProductId, UserId, Score, review title (Summary) and review body (Text).\n",
    "\n",
    "We will combine the review summary and review text into a single combined text. The model will encode this combined text and it will output a single vector embedding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, you will need to install: pandas, openai, transformers, plotly, matplotlib, scikit-learn, torch (transformer dep), torchvision, and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: openai in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (1.58.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (1.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (1.14.1)\n",
      "Requirement already satisfied: torch in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (2.3.1.post100)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from torch) (72.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/ml-tutorials/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, sympy, safetensors, torch, plotly, huggingface-hub, torchvision, tokenizers, transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1.post100\n",
      "    Uninstalling torch-2.3.1.post100:\n",
      "      Successfully uninstalled torch-2.3.1.post100\n",
      "Successfully installed huggingface-hub-0.27.0 plotly-5.24.1 safetensors-0.4.5 sympy-1.13.1 tenacity-9.0.0 tokenizers-0.21.0 torch-2.5.1 torchvision-0.20.1 transformers-4.47.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openai transformers plotly matplotlib scikit-learn torchvision scipy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    import tiktoken\n",
    "except ImportError:\n",
    "    !pip install tiktoken\n",
    "    import tiktoken\n",
    "\n",
    "from utils.embeddings_utils import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = \"text-embedding-3-small\"\n",
    "embedding_encoding = \"cl100k_base\"\n",
    "max_tokens = 8000  # the maximum for text-embedding-3-small is 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B003XPF9BO</td>\n",
       "      <td>A3R7JR3FMEBXQB</td>\n",
       "      <td>5</td>\n",
       "      <td>where does one  start...and stop... with a tre...</td>\n",
       "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
       "      <td>Title: where does one  start...and stop... wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1351123200</td>\n",
       "      <td>B003JK537S</td>\n",
       "      <td>A3JBPC3WFUT5ZP</td>\n",
       "      <td>1</td>\n",
       "      <td>Arrived in pieces</td>\n",
       "      <td>Not pleased at all. When I opened the box, mos...</td>\n",
       "      <td>Title: Arrived in pieces; Content: Not pleased...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time   ProductId          UserId  Score  \\\n",
       "0  1351123200  B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
       "1  1351123200  B003JK537S  A3JBPC3WFUT5ZP      1   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  where does one  start...and stop... with a tre...   \n",
       "1                                  Arrived in pieces   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Wanted to save some to bring to my Chicago fam...   \n",
       "1  Not pleased at all. When I opened the box, mos...   \n",
       "\n",
       "                                            combined  \n",
       "0  Title: where does one  start...and stop... wit...  \n",
       "1  Title: Arrived in pieces; Content: Not pleased...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load & inspect dataset\n",
    "input_datapath = \"data/fine_food_reviews_1k.csv\"  # to save space, we provide a pre-filtered dataset\n",
    "df = pd.read_csv(input_datapath, index_col=0)\n",
    "df = df[[\"Time\", \"ProductId\", \"UserId\", \"Score\", \"Summary\", \"Text\"]]\n",
    "df = df.dropna()\n",
    "df[\"combined\"] = (\n",
    "    \"Title: \" + df.Summary.str.strip() + \"; Content: \" + df.Text.str.strip()\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample to 1k most recent reviews and remove samples that are too long\n",
    "top_n = 1000\n",
    "df = df.sort_values(\"Time\").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out\n",
    "df.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "# omit reviews that are too long to embed\n",
    "df[\"n_tokens\"] = df.combined.apply(lambda x: len(encoding.encode(x)))\n",
    "df = df[df.n_tokens <= max_tokens].tail(top_n)\n",
    "len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get embeddings and save them for future reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
    "\n",
    "# This may take a few minutes\n",
    "df[\"embedding\"] = df.combined.apply(lambda x: get_embedding(x, model=embedding_model))\n",
    "df.to_csv(\"data/fine_food_reviews_with_embeddings_1k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_embedding(\"hi\", model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>combined</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B003XPF9BO</td>\n",
       "      <td>A3R7JR3FMEBXQB</td>\n",
       "      <td>5</td>\n",
       "      <td>where does one  start...and stop... with a tre...</td>\n",
       "      <td>Wanted to save some to bring to my Chicago fam...</td>\n",
       "      <td>Title: where does one  start...and stop... wit...</td>\n",
       "      <td>52</td>\n",
       "      <td>[0.03598902374505997, -0.02119247429072857, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>B003VXHGPK</td>\n",
       "      <td>A21VWSCGW7UUAR</td>\n",
       "      <td>4</td>\n",
       "      <td>Good, but not Wolfgang Puck good</td>\n",
       "      <td>Honestly, I have to admit that I expected a li...</td>\n",
       "      <td>Title: Good, but not Wolfgang Puck good; Conte...</td>\n",
       "      <td>178</td>\n",
       "      <td>[-0.07047832757234573, -0.03178860619664192, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>B008JKTTUA</td>\n",
       "      <td>A34XBAIFT02B60</td>\n",
       "      <td>1</td>\n",
       "      <td>Should advertise coconut as an ingredient more...</td>\n",
       "      <td>First, these should be called Mac - Coconut ba...</td>\n",
       "      <td>Title: Should advertise coconut as an ingredie...</td>\n",
       "      <td>78</td>\n",
       "      <td>[0.05688195675611496, -0.005452037788927555, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>B000LKTTTW</td>\n",
       "      <td>A14MQ40CCU8B13</td>\n",
       "      <td>5</td>\n",
       "      <td>Best tomato soup</td>\n",
       "      <td>I have a hard time finding packaged food of an...</td>\n",
       "      <td>Title: Best tomato soup; Content: I have a har...</td>\n",
       "      <td>111</td>\n",
       "      <td>[-0.01123595330864191, -0.049721892923116684, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>B001D09KAM</td>\n",
       "      <td>A34XBAIFT02B60</td>\n",
       "      <td>1</td>\n",
       "      <td>Should advertise coconut as an ingredient more...</td>\n",
       "      <td>First, these should be called Mac - Coconut ba...</td>\n",
       "      <td>Title: Should advertise coconut as an ingredie...</td>\n",
       "      <td>78</td>\n",
       "      <td>[0.05688195675611496, -0.005452037788927555, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>B0000CFXYA</td>\n",
       "      <td>A3GS4GWPIBV0NT</td>\n",
       "      <td>1</td>\n",
       "      <td>Strange inflammation response</td>\n",
       "      <td>Truthfully wasn't crazy about the taste of the...</td>\n",
       "      <td>Title: Strange inflammation response; Content:...</td>\n",
       "      <td>110</td>\n",
       "      <td>[-0.047974538058042526, 0.04624320939183235, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>B0001BH5YM</td>\n",
       "      <td>A1BZ3HMAKK0NC</td>\n",
       "      <td>5</td>\n",
       "      <td>My favorite and only  MUSTARD</td>\n",
       "      <td>You've just got to experience this mustard... ...</td>\n",
       "      <td>Title: My favorite and only  MUSTARD; Content:...</td>\n",
       "      <td>80</td>\n",
       "      <td>[0.026551488786935806, -0.027489230036735535, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>B0009ET7TC</td>\n",
       "      <td>A2FSDQY5AI6TNX</td>\n",
       "      <td>5</td>\n",
       "      <td>My furbabies LOVE these!</td>\n",
       "      <td>Shake the container and they come running. Eve...</td>\n",
       "      <td>Title: My furbabies LOVE these!; Content: Shak...</td>\n",
       "      <td>47</td>\n",
       "      <td>[-0.011011081747710705, -0.029069731011986732,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>B007PA32L2</td>\n",
       "      <td>A15FF2P7RPKH6G</td>\n",
       "      <td>5</td>\n",
       "      <td>got this for the daughter</td>\n",
       "      <td>all i have heard since she got a kuerig is why...</td>\n",
       "      <td>Title: got this for the daughter; Content: all...</td>\n",
       "      <td>50</td>\n",
       "      <td>[-0.0058360924012959, 0.021187180653214455, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>B001EQ5GEO</td>\n",
       "      <td>A3VYU0VO6DYV6I</td>\n",
       "      <td>5</td>\n",
       "      <td>I love Maui Coffee!</td>\n",
       "      <td>My first experience with Maui Coffee was bring...</td>\n",
       "      <td>Title: I love Maui Coffee!; Content: My first ...</td>\n",
       "      <td>118</td>\n",
       "      <td>[0.019213637337088585, -0.019265741109848022, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ProductId          UserId  Score  \\\n",
       "0    B003XPF9BO  A3R7JR3FMEBXQB      5   \n",
       "297  B003VXHGPK  A21VWSCGW7UUAR      4   \n",
       "296  B008JKTTUA  A34XBAIFT02B60      1   \n",
       "295  B000LKTTTW  A14MQ40CCU8B13      5   \n",
       "294  B001D09KAM  A34XBAIFT02B60      1   \n",
       "..          ...             ...    ...   \n",
       "623  B0000CFXYA  A3GS4GWPIBV0NT      1   \n",
       "624  B0001BH5YM   A1BZ3HMAKK0NC      5   \n",
       "625  B0009ET7TC  A2FSDQY5AI6TNX      5   \n",
       "619  B007PA32L2  A15FF2P7RPKH6G      5   \n",
       "999  B001EQ5GEO  A3VYU0VO6DYV6I      5   \n",
       "\n",
       "                                               Summary  \\\n",
       "0    where does one  start...and stop... with a tre...   \n",
       "297                   Good, but not Wolfgang Puck good   \n",
       "296  Should advertise coconut as an ingredient more...   \n",
       "295                                   Best tomato soup   \n",
       "294  Should advertise coconut as an ingredient more...   \n",
       "..                                                 ...   \n",
       "623                      Strange inflammation response   \n",
       "624                      My favorite and only  MUSTARD   \n",
       "625                           My furbabies LOVE these!   \n",
       "619                          got this for the daughter   \n",
       "999                                I love Maui Coffee!   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    Wanted to save some to bring to my Chicago fam...   \n",
       "297  Honestly, I have to admit that I expected a li...   \n",
       "296  First, these should be called Mac - Coconut ba...   \n",
       "295  I have a hard time finding packaged food of an...   \n",
       "294  First, these should be called Mac - Coconut ba...   \n",
       "..                                                 ...   \n",
       "623  Truthfully wasn't crazy about the taste of the...   \n",
       "624  You've just got to experience this mustard... ...   \n",
       "625  Shake the container and they come running. Eve...   \n",
       "619  all i have heard since she got a kuerig is why...   \n",
       "999  My first experience with Maui Coffee was bring...   \n",
       "\n",
       "                                              combined  n_tokens  \\\n",
       "0    Title: where does one  start...and stop... wit...        52   \n",
       "297  Title: Good, but not Wolfgang Puck good; Conte...       178   \n",
       "296  Title: Should advertise coconut as an ingredie...        78   \n",
       "295  Title: Best tomato soup; Content: I have a har...       111   \n",
       "294  Title: Should advertise coconut as an ingredie...        78   \n",
       "..                                                 ...       ...   \n",
       "623  Title: Strange inflammation response; Content:...       110   \n",
       "624  Title: My favorite and only  MUSTARD; Content:...        80   \n",
       "625  Title: My furbabies LOVE these!; Content: Shak...        47   \n",
       "619  Title: got this for the daughter; Content: all...        50   \n",
       "999  Title: I love Maui Coffee!; Content: My first ...       118   \n",
       "\n",
       "                                             embedding  \n",
       "0    [0.03598902374505997, -0.02119247429072857, -0...  \n",
       "297  [-0.07047832757234573, -0.03178860619664192, -...  \n",
       "296  [0.05688195675611496, -0.005452037788927555, 0...  \n",
       "295  [-0.01123595330864191, -0.049721892923116684, ...  \n",
       "294  [0.05688195675611496, -0.005452037788927555, 0...  \n",
       "..                                                 ...  \n",
       "623  [-0.047974538058042526, 0.04624320939183235, 0...  \n",
       "624  [0.026551488786935806, -0.027489230036735535, ...  \n",
       "625  [-0.011011081747710705, -0.029069731011986732,...  \n",
       "619  [-0.0058360924012959, 0.021187180653214455, -0...  \n",
       "999  [0.019213637337088585, -0.019265741109848022, ...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1536\n",
       "297    1536\n",
       "296    1536\n",
       "295    1536\n",
       "294    1536\n",
       "       ... \n",
       "623    1536\n",
       "624    1536\n",
       "625    1536\n",
       "619    1536\n",
       "999    1536\n",
       "Name: embedding, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embedding\"].apply(lambda x: len(x))# so the embeddings are a 1536 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
